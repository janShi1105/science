{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "402a0d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_wide = pd.read_csv('./input/ch03/time_series_wide.csv', index_col = 0)\n",
    "df_wide.index = pd.to_datetime(df_wide.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21117c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              A     B     C\n",
      "2016-07-01  532  3314  1136\n",
      "2016-07-02  798  2461  1188\n",
      "2016-07-03  823  3522  1711\n",
      "2016-07-04  937  5451  1977\n",
      "2016-07-05  881  4729  1975\n"
     ]
    }
   ],
   "source": [
    "print(df_wide.iloc[:5,:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "658f8698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long = df_wide.stack().reset_index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9af2e1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           level_1     0\n",
      "2016-07-01       A   532\n",
      "2016-07-01       B  3314\n",
      "2016-07-01       C  1136\n",
      "2016-07-02       A   798\n",
      "2016-07-02       B  2461\n",
      "...            ...   ...\n",
      "2016-12-30       B  4243\n",
      "2016-12-30       C  2069\n",
      "2016-12-31       A   869\n",
      "2016-12-31       B  4703\n",
      "2016-12-31       C  2233\n",
      "\n",
      "[552 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31d558a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_long.columns = ['id', 'value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c6dbc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           id  value\n",
      "2016-07-01  A    532\n",
      "2016-07-01  B   3314\n",
      "2016-07-01  C   1136\n",
      "2016-07-02  A    798\n",
      "2016-07-02  B   2461\n",
      "...        ..    ...\n",
      "2016-12-30  B   4243\n",
      "2016-12-30  C   2069\n",
      "2016-12-31  A    869\n",
      "2016-12-31  B   4703\n",
      "2016-12-31  C   2233\n",
      "\n",
      "[552 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfe41adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wide = df_long.pivot(index=None, columns='id', values='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd68d0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id            A     B     C\n",
      "2016-07-01  532  3314  1136\n",
      "2016-07-02  798  2461  1188\n",
      "2016-07-03  823  3522  1711\n",
      "2016-07-04  937  5451  1977\n",
      "2016-07-05  881  4729  1975\n",
      "...         ...   ...   ...\n",
      "2016-12-27  840  4573  1850\n",
      "2016-12-28  943  4511  1764\n",
      "2016-12-29  978  4599  1787\n",
      "2016-12-30  907  4243  2069\n",
      "2016-12-31  869  4703  2233\n",
      "\n",
      "[184 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_wide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4caf01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./input/sample-data/train_preprocessed.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('./input/sample-data/test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29e33dd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>product</th>\n",
       "      <th>amount</th>\n",
       "      <th>medical_info_a1</th>\n",
       "      <th>medical_info_a2</th>\n",
       "      <th>medical_info_a3</th>\n",
       "      <th>medical_info_b1</th>\n",
       "      <th>...</th>\n",
       "      <th>medical_keyword_5</th>\n",
       "      <th>medical_keyword_6</th>\n",
       "      <th>medical_keyword_7</th>\n",
       "      <th>medical_keyword_8</th>\n",
       "      <th>medical_keyword_9</th>\n",
       "      <th>medical_keyword_10</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>yearmonth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>166.445608</td>\n",
       "      <td>65.016732</td>\n",
       "      <td>9</td>\n",
       "      <td>7000000</td>\n",
       "      <td>134</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>24182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>164.334615</td>\n",
       "      <td>56.544217</td>\n",
       "      <td>0</td>\n",
       "      <td>7000000</td>\n",
       "      <td>438</td>\n",
       "      <td>263</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>24185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>167.462917</td>\n",
       "      <td>54.242267</td>\n",
       "      <td>2</td>\n",
       "      <td>6000000</td>\n",
       "      <td>313</td>\n",
       "      <td>325</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>24194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>177.097725</td>\n",
       "      <td>71.147762</td>\n",
       "      <td>3</td>\n",
       "      <td>8000000</td>\n",
       "      <td>342</td>\n",
       "      <td>213</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>24187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>158.165788</td>\n",
       "      <td>65.240697</td>\n",
       "      <td>1</td>\n",
       "      <td>9000000</td>\n",
       "      <td>327</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>24201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex      height     weight  product   amount  medical_info_a1  \\\n",
       "0   50    1  166.445608  65.016732        9  7000000              134   \n",
       "1   68    0  164.334615  56.544217        0  7000000              438   \n",
       "2   77    1  167.462917  54.242267        2  6000000              313   \n",
       "3   17    1  177.097725  71.147762        3  8000000              342   \n",
       "4   62    0  158.165788  65.240697        1  9000000              327   \n",
       "\n",
       "   medical_info_a2  medical_info_a3  medical_info_b1  ...  medical_keyword_5  \\\n",
       "0              202                1               11  ...                  0   \n",
       "1              263                3               14  ...                  0   \n",
       "2              325                1               18  ...                  0   \n",
       "3              213                2               11  ...                  0   \n",
       "4              102                0               14  ...                  0   \n",
       "\n",
       "   medical_keyword_6  medical_keyword_7  medical_keyword_8  medical_keyword_9  \\\n",
       "0                  1                  0                  1                  0   \n",
       "1                  0                  1                  1                  0   \n",
       "2                  1                  0                  1                  0   \n",
       "3                  0                  0                  1                  0   \n",
       "4                  0                  1                  1                  1   \n",
       "\n",
       "   medical_keyword_10  year  month  day  yearmonth  \n",
       "0                   0  2015      2    3      24182  \n",
       "1                   0  2015      5    9      24185  \n",
       "2                   0  2016      2   13      24194  \n",
       "3                   0  2015      7    6      24187  \n",
       "4                   0  2016      9   17      24201  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True , random_state=71)\n",
    "tr_idx, va_idx = list(kf.split(train_x))[0]\n",
    "tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "tr_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e505d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:06:37] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-3.7/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-logloss:0.54088\teval-logloss:0.55003\n",
      "[1]\ttrain-logloss:0.45269\teval-logloss:0.47182\n",
      "[2]\ttrain-logloss:0.39482\teval-logloss:0.42026\n",
      "[3]\ttrain-logloss:0.35198\teval-logloss:0.38520\n",
      "[4]\ttrain-logloss:0.32021\teval-logloss:0.36150\n",
      "[5]\ttrain-logloss:0.29673\teval-logloss:0.34463\n",
      "[6]\ttrain-logloss:0.27610\teval-logloss:0.32900\n",
      "[7]\ttrain-logloss:0.25886\teval-logloss:0.31670\n",
      "[8]\ttrain-logloss:0.24363\teval-logloss:0.30775\n",
      "[9]\ttrain-logloss:0.23153\teval-logloss:0.30093\n",
      "[10]\ttrain-logloss:0.22016\teval-logloss:0.29413\n",
      "[11]\ttrain-logloss:0.20963\teval-logloss:0.28528\n",
      "[12]\ttrain-logloss:0.19951\teval-logloss:0.27912\n",
      "[13]\ttrain-logloss:0.19324\teval-logloss:0.27642\n",
      "[14]\ttrain-logloss:0.18547\teval-logloss:0.27154\n",
      "[15]\ttrain-logloss:0.17474\teval-logloss:0.26516\n",
      "[16]\ttrain-logloss:0.16900\teval-logloss:0.26089\n",
      "[17]\ttrain-logloss:0.16323\teval-logloss:0.25849\n",
      "[18]\ttrain-logloss:0.15950\teval-logloss:0.25691\n",
      "[19]\ttrain-logloss:0.15637\teval-logloss:0.25511\n",
      "[20]\ttrain-logloss:0.14722\teval-logloss:0.25035\n",
      "[21]\ttrain-logloss:0.14290\teval-logloss:0.24734\n",
      "[22]\ttrain-logloss:0.13782\teval-logloss:0.24612\n",
      "[23]\ttrain-logloss:0.13362\teval-logloss:0.24387\n",
      "[24]\ttrain-logloss:0.13047\teval-logloss:0.24251\n",
      "[25]\ttrain-logloss:0.12654\teval-logloss:0.24094\n",
      "[26]\ttrain-logloss:0.12268\teval-logloss:0.24005\n",
      "[27]\ttrain-logloss:0.11966\teval-logloss:0.23803\n",
      "[28]\ttrain-logloss:0.11506\teval-logloss:0.23699\n",
      "[29]\ttrain-logloss:0.11027\teval-logloss:0.23626\n",
      "[30]\ttrain-logloss:0.10827\teval-logloss:0.23621\n",
      "[31]\ttrain-logloss:0.10262\teval-logloss:0.23269\n",
      "[32]\ttrain-logloss:0.10062\teval-logloss:0.23212\n",
      "[33]\ttrain-logloss:0.09913\teval-logloss:0.23180\n",
      "[34]\ttrain-logloss:0.09582\teval-logloss:0.23184\n",
      "[35]\ttrain-logloss:0.09378\teval-logloss:0.22998\n",
      "[36]\ttrain-logloss:0.09243\teval-logloss:0.22980\n",
      "[37]\ttrain-logloss:0.08952\teval-logloss:0.22913\n",
      "[38]\ttrain-logloss:0.08732\teval-logloss:0.22870\n",
      "[39]\ttrain-logloss:0.08576\teval-logloss:0.22786\n",
      "[40]\ttrain-logloss:0.08340\teval-logloss:0.22857\n",
      "[41]\ttrain-logloss:0.08125\teval-logloss:0.22695\n",
      "[42]\ttrain-logloss:0.08027\teval-logloss:0.22646\n",
      "[43]\ttrain-logloss:0.07829\teval-logloss:0.22660\n",
      "[44]\ttrain-logloss:0.07616\teval-logloss:0.22607\n",
      "[45]\ttrain-logloss:0.07522\teval-logloss:0.22499\n",
      "[46]\ttrain-logloss:0.07313\teval-logloss:0.22316\n",
      "[47]\ttrain-logloss:0.07198\teval-logloss:0.22293\n",
      "[48]\ttrain-logloss:0.07026\teval-logloss:0.22265\n",
      "[49]\ttrain-logloss:0.06948\teval-logloss:0.22226\n",
      "logloss: 0.2223\n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(tr_x, label=tr_y)\n",
    "dvalid = xgb.DMatrix(va_x, label=va_y)\n",
    "dtest = xgb.DMatrix(test_x)\n",
    "\n",
    "params = {'objective':  'binary:logistic', 'silent': 1, 'random_state': 71}\n",
    "num_round = 50\n",
    "\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "model = xgb.train(params, dtrain, num_round, evals=watchlist)\n",
    "\n",
    "va_pred = model.predict(dvalid)\n",
    "score=log_loss(va_y, va_pred)\n",
    "print(f'logloss: {score:.4f}')\n",
    "\n",
    "pred = model.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b675ebbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05d54e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:11:40] WARNING: /Users/runner/work/xgboost/xgboost/python-package/build/temp.macosx-10.9-x86_64-3.7/xgboost/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\ttrain-logloss:0.54088\teval-logloss:0.55003\n",
      "[1]\ttrain-logloss:0.45269\teval-logloss:0.47182\n",
      "[2]\ttrain-logloss:0.39482\teval-logloss:0.42026\n",
      "[3]\ttrain-logloss:0.35198\teval-logloss:0.38520\n",
      "[4]\ttrain-logloss:0.32021\teval-logloss:0.36150\n",
      "[5]\ttrain-logloss:0.29673\teval-logloss:0.34463\n",
      "[6]\ttrain-logloss:0.27610\teval-logloss:0.32900\n",
      "[7]\ttrain-logloss:0.25886\teval-logloss:0.31670\n",
      "[8]\ttrain-logloss:0.24363\teval-logloss:0.30775\n",
      "[9]\ttrain-logloss:0.23153\teval-logloss:0.30093\n",
      "[10]\ttrain-logloss:0.22016\teval-logloss:0.29413\n",
      "[11]\ttrain-logloss:0.20963\teval-logloss:0.28528\n",
      "[12]\ttrain-logloss:0.19951\teval-logloss:0.27912\n",
      "[13]\ttrain-logloss:0.19324\teval-logloss:0.27642\n",
      "[14]\ttrain-logloss:0.18547\teval-logloss:0.27154\n",
      "[15]\ttrain-logloss:0.17474\teval-logloss:0.26516\n",
      "[16]\ttrain-logloss:0.16900\teval-logloss:0.26089\n",
      "[17]\ttrain-logloss:0.16323\teval-logloss:0.25849\n",
      "[18]\ttrain-logloss:0.15950\teval-logloss:0.25691\n",
      "[19]\ttrain-logloss:0.15637\teval-logloss:0.25511\n",
      "[20]\ttrain-logloss:0.14722\teval-logloss:0.25035\n",
      "[21]\ttrain-logloss:0.14290\teval-logloss:0.24734\n",
      "[22]\ttrain-logloss:0.13782\teval-logloss:0.24612\n",
      "[23]\ttrain-logloss:0.13362\teval-logloss:0.24387\n",
      "[24]\ttrain-logloss:0.13047\teval-logloss:0.24251\n",
      "[25]\ttrain-logloss:0.12654\teval-logloss:0.24094\n",
      "[26]\ttrain-logloss:0.12268\teval-logloss:0.24005\n",
      "[27]\ttrain-logloss:0.11966\teval-logloss:0.23803\n",
      "[28]\ttrain-logloss:0.11506\teval-logloss:0.23699\n",
      "[29]\ttrain-logloss:0.11027\teval-logloss:0.23626\n",
      "[30]\ttrain-logloss:0.10827\teval-logloss:0.23621\n",
      "[31]\ttrain-logloss:0.10262\teval-logloss:0.23269\n",
      "[32]\ttrain-logloss:0.10062\teval-logloss:0.23212\n",
      "[33]\ttrain-logloss:0.09913\teval-logloss:0.23180\n",
      "[34]\ttrain-logloss:0.09582\teval-logloss:0.23184\n",
      "[35]\ttrain-logloss:0.09378\teval-logloss:0.22998\n",
      "[36]\ttrain-logloss:0.09243\teval-logloss:0.22980\n",
      "[37]\ttrain-logloss:0.08952\teval-logloss:0.22913\n",
      "[38]\ttrain-logloss:0.08732\teval-logloss:0.22870\n",
      "[39]\ttrain-logloss:0.08576\teval-logloss:0.22786\n",
      "[40]\ttrain-logloss:0.08340\teval-logloss:0.22857\n",
      "[41]\ttrain-logloss:0.08125\teval-logloss:0.22695\n",
      "[42]\ttrain-logloss:0.08027\teval-logloss:0.22646\n",
      "[43]\ttrain-logloss:0.07829\teval-logloss:0.22660\n",
      "[44]\ttrain-logloss:0.07616\teval-logloss:0.22607\n",
      "[45]\ttrain-logloss:0.07522\teval-logloss:0.22499\n",
      "[46]\ttrain-logloss:0.07313\teval-logloss:0.22316\n",
      "[47]\ttrain-logloss:0.07198\teval-logloss:0.22293\n",
      "[48]\ttrain-logloss:0.07026\teval-logloss:0.22265\n",
      "[49]\ttrain-logloss:0.06948\teval-logloss:0.22226\n",
      "[50]\ttrain-logloss:0.06725\teval-logloss:0.22227\n",
      "[51]\ttrain-logloss:0.06608\teval-logloss:0.22189\n",
      "[52]\ttrain-logloss:0.06474\teval-logloss:0.22258\n",
      "[53]\ttrain-logloss:0.06343\teval-logloss:0.22279\n",
      "[54]\ttrain-logloss:0.06259\teval-logloss:0.22280\n",
      "[55]\ttrain-logloss:0.06163\teval-logloss:0.22262\n",
      "[56]\ttrain-logloss:0.06056\teval-logloss:0.22149\n",
      "[57]\ttrain-logloss:0.05859\teval-logloss:0.22114\n",
      "[58]\ttrain-logloss:0.05796\teval-logloss:0.22093\n",
      "[59]\ttrain-logloss:0.05692\teval-logloss:0.21983\n",
      "[60]\ttrain-logloss:0.05564\teval-logloss:0.22027\n",
      "[61]\ttrain-logloss:0.05500\teval-logloss:0.22076\n",
      "[62]\ttrain-logloss:0.05393\teval-logloss:0.22038\n",
      "[63]\ttrain-logloss:0.05339\teval-logloss:0.22014\n",
      "[64]\ttrain-logloss:0.05252\teval-logloss:0.21951\n",
      "[65]\ttrain-logloss:0.05096\teval-logloss:0.21760\n",
      "[66]\ttrain-logloss:0.05005\teval-logloss:0.21717\n",
      "[67]\ttrain-logloss:0.04909\teval-logloss:0.21699\n",
      "[68]\ttrain-logloss:0.04820\teval-logloss:0.21623\n",
      "[69]\ttrain-logloss:0.04725\teval-logloss:0.21541\n",
      "[70]\ttrain-logloss:0.04671\teval-logloss:0.21559\n",
      "[71]\ttrain-logloss:0.04575\teval-logloss:0.21541\n",
      "[72]\ttrain-logloss:0.04463\teval-logloss:0.21407\n",
      "[73]\ttrain-logloss:0.04405\teval-logloss:0.21397\n",
      "[74]\ttrain-logloss:0.04301\teval-logloss:0.21496\n",
      "[75]\ttrain-logloss:0.04262\teval-logloss:0.21554\n",
      "[76]\ttrain-logloss:0.04218\teval-logloss:0.21631\n",
      "[77]\ttrain-logloss:0.04157\teval-logloss:0.21579\n",
      "[78]\ttrain-logloss:0.04077\teval-logloss:0.21591\n",
      "[79]\ttrain-logloss:0.04003\teval-logloss:0.21606\n",
      "[80]\ttrain-logloss:0.03972\teval-logloss:0.21642\n",
      "[81]\ttrain-logloss:0.03874\teval-logloss:0.21528\n",
      "[82]\ttrain-logloss:0.03837\teval-logloss:0.21606\n",
      "[83]\ttrain-logloss:0.03807\teval-logloss:0.21593\n",
      "[84]\ttrain-logloss:0.03737\teval-logloss:0.21665\n",
      "[85]\ttrain-logloss:0.03669\teval-logloss:0.21784\n",
      "[86]\ttrain-logloss:0.03576\teval-logloss:0.21918\n",
      "[87]\ttrain-logloss:0.03553\teval-logloss:0.21912\n",
      "[88]\ttrain-logloss:0.03480\teval-logloss:0.21967\n",
      "[89]\ttrain-logloss:0.03425\teval-logloss:0.21976\n",
      "[90]\ttrain-logloss:0.03402\teval-logloss:0.21996\n",
      "[91]\ttrain-logloss:0.03342\teval-logloss:0.21972\n",
      "[92]\ttrain-logloss:0.03248\teval-logloss:0.21991\n",
      "[93]\ttrain-logloss:0.03195\teval-logloss:0.21962\n"
     ]
    }
   ],
   "source": [
    "params = {'objective': 'binary:logistic', 'silent': 1, 'random_state': 71, 'eval_metric': 'logloss'}\n",
    "num_round= 500\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "model = xgb.train(params, dtrain, num_round, evals=watchlist, early_stopping_rounds=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b10bad69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kazuyaaoki/.pyenv/versions/3.10.3/lib/python3.10/site-packages/lightgbm/basic.py:2068: UserWarning: categorical_feature in Dataset is overridden.\n",
      "New categorical_feature is ['medical_info_b2', 'medical_info_b3', 'product']\n",
      "  _log_warning('categorical_feature in Dataset is overridden.\\n'\n",
      "/Users/kazuyaaoki/.pyenv/versions/3.10.3/lib/python3.10/site-packages/lightgbm/basic.py:1780: UserWarning: Overriding the parameters from Reference Dataset.\n",
      "  _log_warning('Overriding the parameters from Reference Dataset.')\n",
      "/Users/kazuyaaoki/.pyenv/versions/3.10.3/lib/python3.10/site-packages/lightgbm/basic.py:1513: UserWarning: categorical_column in param dict is overridden.\n",
      "  _log_warning(f'{cat_alias} in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.002530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[1]\ttrain's binary_logloss: 0.454286\tvalid's binary_logloss: 0.4654\n",
      "[2]\ttrain's binary_logloss: 0.429348\tvalid's binary_logloss: 0.443537\n",
      "[3]\ttrain's binary_logloss: 0.409269\tvalid's binary_logloss: 0.425588\n",
      "[4]\ttrain's binary_logloss: 0.393109\tvalid's binary_logloss: 0.411213\n",
      "[5]\ttrain's binary_logloss: 0.379351\tvalid's binary_logloss: 0.399341\n",
      "[6]\ttrain's binary_logloss: 0.366138\tvalid's binary_logloss: 0.389055\n",
      "[7]\ttrain's binary_logloss: 0.35417\tvalid's binary_logloss: 0.378254\n",
      "[8]\ttrain's binary_logloss: 0.343782\tvalid's binary_logloss: 0.370131\n",
      "[9]\ttrain's binary_logloss: 0.334283\tvalid's binary_logloss: 0.362036\n",
      "[10]\ttrain's binary_logloss: 0.324802\tvalid's binary_logloss: 0.353452\n",
      "[11]\ttrain's binary_logloss: 0.316592\tvalid's binary_logloss: 0.346904\n",
      "[12]\ttrain's binary_logloss: 0.308484\tvalid's binary_logloss: 0.340248\n",
      "[13]\ttrain's binary_logloss: 0.301468\tvalid's binary_logloss: 0.335801\n",
      "[14]\ttrain's binary_logloss: 0.294674\tvalid's binary_logloss: 0.330487\n",
      "[15]\ttrain's binary_logloss: 0.288251\tvalid's binary_logloss: 0.325634\n",
      "[16]\ttrain's binary_logloss: 0.282225\tvalid's binary_logloss: 0.321448\n",
      "[17]\ttrain's binary_logloss: 0.277045\tvalid's binary_logloss: 0.318027\n",
      "[18]\ttrain's binary_logloss: 0.271694\tvalid's binary_logloss: 0.31501\n",
      "[19]\ttrain's binary_logloss: 0.265931\tvalid's binary_logloss: 0.311018\n",
      "[20]\ttrain's binary_logloss: 0.261148\tvalid's binary_logloss: 0.307548\n",
      "[21]\ttrain's binary_logloss: 0.255397\tvalid's binary_logloss: 0.30346\n",
      "[22]\ttrain's binary_logloss: 0.25054\tvalid's binary_logloss: 0.299063\n",
      "[23]\ttrain's binary_logloss: 0.245472\tvalid's binary_logloss: 0.295614\n",
      "[24]\ttrain's binary_logloss: 0.241049\tvalid's binary_logloss: 0.292596\n",
      "[25]\ttrain's binary_logloss: 0.237346\tvalid's binary_logloss: 0.289802\n",
      "[26]\ttrain's binary_logloss: 0.233644\tvalid's binary_logloss: 0.287015\n",
      "[27]\ttrain's binary_logloss: 0.229771\tvalid's binary_logloss: 0.285147\n",
      "[28]\ttrain's binary_logloss: 0.225304\tvalid's binary_logloss: 0.281868\n",
      "[29]\ttrain's binary_logloss: 0.221761\tvalid's binary_logloss: 0.279715\n",
      "[30]\ttrain's binary_logloss: 0.218152\tvalid's binary_logloss: 0.276755\n",
      "[31]\ttrain's binary_logloss: 0.214731\tvalid's binary_logloss: 0.274906\n",
      "[32]\ttrain's binary_logloss: 0.21187\tvalid's binary_logloss: 0.273533\n",
      "[33]\ttrain's binary_logloss: 0.208913\tvalid's binary_logloss: 0.271975\n",
      "[34]\ttrain's binary_logloss: 0.205932\tvalid's binary_logloss: 0.269754\n",
      "[35]\ttrain's binary_logloss: 0.20259\tvalid's binary_logloss: 0.267191\n",
      "[36]\ttrain's binary_logloss: 0.199625\tvalid's binary_logloss: 0.265015\n",
      "[37]\ttrain's binary_logloss: 0.197027\tvalid's binary_logloss: 0.264288\n",
      "[38]\ttrain's binary_logloss: 0.193946\tvalid's binary_logloss: 0.263265\n",
      "[39]\ttrain's binary_logloss: 0.191536\tvalid's binary_logloss: 0.262294\n",
      "[40]\ttrain's binary_logloss: 0.188342\tvalid's binary_logloss: 0.259765\n",
      "[41]\ttrain's binary_logloss: 0.185896\tvalid's binary_logloss: 0.257982\n",
      "[42]\ttrain's binary_logloss: 0.183334\tvalid's binary_logloss: 0.257238\n",
      "[43]\ttrain's binary_logloss: 0.181354\tvalid's binary_logloss: 0.256282\n",
      "[44]\ttrain's binary_logloss: 0.17922\tvalid's binary_logloss: 0.255055\n",
      "[45]\ttrain's binary_logloss: 0.176956\tvalid's binary_logloss: 0.253577\n",
      "[46]\ttrain's binary_logloss: 0.174588\tvalid's binary_logloss: 0.252098\n",
      "[47]\ttrain's binary_logloss: 0.172249\tvalid's binary_logloss: 0.250808\n",
      "[48]\ttrain's binary_logloss: 0.169526\tvalid's binary_logloss: 0.249644\n",
      "[49]\ttrain's binary_logloss: 0.167526\tvalid's binary_logloss: 0.24889\n",
      "[50]\ttrain's binary_logloss: 0.16545\tvalid's binary_logloss: 0.24807\n",
      "[51]\ttrain's binary_logloss: 0.162881\tvalid's binary_logloss: 0.245714\n",
      "[52]\ttrain's binary_logloss: 0.160862\tvalid's binary_logloss: 0.24506\n",
      "[53]\ttrain's binary_logloss: 0.158953\tvalid's binary_logloss: 0.244376\n",
      "[54]\ttrain's binary_logloss: 0.15685\tvalid's binary_logloss: 0.242814\n",
      "[55]\ttrain's binary_logloss: 0.155006\tvalid's binary_logloss: 0.241794\n",
      "[56]\ttrain's binary_logloss: 0.152759\tvalid's binary_logloss: 0.240173\n",
      "[57]\ttrain's binary_logloss: 0.150735\tvalid's binary_logloss: 0.239338\n",
      "[58]\ttrain's binary_logloss: 0.149108\tvalid's binary_logloss: 0.238941\n",
      "[59]\ttrain's binary_logloss: 0.147209\tvalid's binary_logloss: 0.238182\n",
      "[60]\ttrain's binary_logloss: 0.145662\tvalid's binary_logloss: 0.237785\n",
      "[61]\ttrain's binary_logloss: 0.143415\tvalid's binary_logloss: 0.236284\n",
      "[62]\ttrain's binary_logloss: 0.141762\tvalid's binary_logloss: 0.23558\n",
      "[63]\ttrain's binary_logloss: 0.140409\tvalid's binary_logloss: 0.235289\n",
      "[64]\ttrain's binary_logloss: 0.138893\tvalid's binary_logloss: 0.234525\n",
      "[65]\ttrain's binary_logloss: 0.137423\tvalid's binary_logloss: 0.234159\n",
      "[66]\ttrain's binary_logloss: 0.13595\tvalid's binary_logloss: 0.233513\n",
      "[67]\ttrain's binary_logloss: 0.134412\tvalid's binary_logloss: 0.232994\n",
      "[68]\ttrain's binary_logloss: 0.132967\tvalid's binary_logloss: 0.232634\n",
      "[69]\ttrain's binary_logloss: 0.131473\tvalid's binary_logloss: 0.231926\n",
      "[70]\ttrain's binary_logloss: 0.129883\tvalid's binary_logloss: 0.230888\n",
      "[71]\ttrain's binary_logloss: 0.128601\tvalid's binary_logloss: 0.230392\n",
      "[72]\ttrain's binary_logloss: 0.126664\tvalid's binary_logloss: 0.229085\n",
      "[73]\ttrain's binary_logloss: 0.125221\tvalid's binary_logloss: 0.228812\n",
      "[74]\ttrain's binary_logloss: 0.123835\tvalid's binary_logloss: 0.228386\n",
      "[75]\ttrain's binary_logloss: 0.122624\tvalid's binary_logloss: 0.227671\n",
      "[76]\ttrain's binary_logloss: 0.121111\tvalid's binary_logloss: 0.226936\n",
      "[77]\ttrain's binary_logloss: 0.119972\tvalid's binary_logloss: 0.226386\n",
      "[78]\ttrain's binary_logloss: 0.118846\tvalid's binary_logloss: 0.226546\n",
      "[79]\ttrain's binary_logloss: 0.117853\tvalid's binary_logloss: 0.226293\n",
      "[80]\ttrain's binary_logloss: 0.116445\tvalid's binary_logloss: 0.225336\n",
      "[81]\ttrain's binary_logloss: 0.114972\tvalid's binary_logloss: 0.224775\n",
      "[82]\ttrain's binary_logloss: 0.113891\tvalid's binary_logloss: 0.224523\n",
      "[83]\ttrain's binary_logloss: 0.112694\tvalid's binary_logloss: 0.224459\n",
      "[84]\ttrain's binary_logloss: 0.111511\tvalid's binary_logloss: 0.223836\n",
      "[85]\ttrain's binary_logloss: 0.110331\tvalid's binary_logloss: 0.223431\n",
      "[86]\ttrain's binary_logloss: 0.108975\tvalid's binary_logloss: 0.222701\n",
      "[87]\ttrain's binary_logloss: 0.107753\tvalid's binary_logloss: 0.221952\n",
      "[88]\ttrain's binary_logloss: 0.106266\tvalid's binary_logloss: 0.220822\n",
      "[89]\ttrain's binary_logloss: 0.105333\tvalid's binary_logloss: 0.220196\n",
      "[90]\ttrain's binary_logloss: 0.104252\tvalid's binary_logloss: 0.21966\n",
      "[91]\ttrain's binary_logloss: 0.103194\tvalid's binary_logloss: 0.219586\n",
      "[92]\ttrain's binary_logloss: 0.102277\tvalid's binary_logloss: 0.2194\n",
      "[93]\ttrain's binary_logloss: 0.101037\tvalid's binary_logloss: 0.218694\n",
      "[94]\ttrain's binary_logloss: 0.100107\tvalid's binary_logloss: 0.219007\n",
      "[95]\ttrain's binary_logloss: 0.0991938\tvalid's binary_logloss: 0.218588\n",
      "[96]\ttrain's binary_logloss: 0.0980778\tvalid's binary_logloss: 0.217905\n",
      "[97]\ttrain's binary_logloss: 0.0971554\tvalid's binary_logloss: 0.217729\n",
      "[98]\ttrain's binary_logloss: 0.0961875\tvalid's binary_logloss: 0.21756\n",
      "[99]\ttrain's binary_logloss: 0.0953092\tvalid's binary_logloss: 0.217168\n",
      "[100]\ttrain's binary_logloss: 0.0942369\tvalid's binary_logloss: 0.216144\n",
      "logloss:  0.2161\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "lgb_train = lgb.Dataset(tr_x, tr_y)\n",
    "lgb_eval = lgb.Dataset(va_x, va_y)\n",
    "\n",
    "params = {'objective': 'binary', 'seed': 71, 'verbose': 0, 'metrics': 'binary_logloss'}\n",
    "num_round = 100\n",
    "\n",
    "categorical_features = ['product', 'medical_info_b2', 'medical_info_b3']\n",
    "model = lgb.train(params, lgb_train , num_boost_round=num_round, categorical_feature=categorical_features, valid_names=['train', 'valid'], valid_sets=[lgb_train, lgb_eval])\n",
    "\n",
    "va_pred = model.predict(va_x)\n",
    "score = log_loss(va_y, va_pred)\n",
    "print(f'logloss: {score: .4f}')\n",
    "\n",
    "pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c216c261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "59/59 [==============================] - 1s 4ms/step - loss: 0.4399 - accuracy: 0.8211 - val_loss: 0.3852 - val_accuracy: 0.8512\n",
      "Epoch 2/10\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8543 - val_loss: 0.3794 - val_accuracy: 0.8420\n",
      "Epoch 3/10\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8591 - val_loss: 0.3717 - val_accuracy: 0.8448\n",
      "Epoch 4/10\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.3226 - accuracy: 0.8711 - val_loss: 0.3656 - val_accuracy: 0.8492\n",
      "Epoch 5/10\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.3039 - accuracy: 0.8784 - val_loss: 0.3536 - val_accuracy: 0.8548\n",
      "Epoch 6/10\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.8836 - val_loss: 0.3323 - val_accuracy: 0.8592\n",
      "Epoch 7/10\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.8997 - val_loss: 0.3132 - val_accuracy: 0.8648\n",
      "Epoch 8/10\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.2202 - accuracy: 0.9131 - val_loss: 0.2952 - val_accuracy: 0.8740\n",
      "Epoch 9/10\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.1971 - accuracy: 0.9191 - val_loss: 0.2922 - val_accuracy: 0.8788\n",
      "Epoch 10/10\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.1861 - accuracy: 0.9208 - val_loss: 0.3015 - val_accuracy: 0.8788\n",
      "79/79 [==============================] - 0s 827us/step\n",
      "logloss:  0.3015\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "train = pd.read_csv('./input/sample-data/train_preprocessed_onehot.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('./input/sample-data/test_preprocessed_onehot.csv')\n",
    "\n",
    "# 学習データを学習データとバリデーションデータに分ける\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "tr_idx, va_idx = list(kf.split(train_x))[0]\n",
    "tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "scaler = StandardScaler()\n",
    "tr_x = scaler.fit_transform(tr_x)\n",
    "va_x = scaler.transform(va_x)\n",
    "test_x = scaler.transform(test_x)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, activation='relu', input_shape=(train_x.shape[1],)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 128\n",
    "epochs = 10\n",
    "history = model.fit(tr_x, tr_y, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(va_x, va_y))\n",
    "\n",
    "va_pred = model.predict(va_x)\n",
    "score = log_loss(va_y, va_pred, eps=1e-7)\n",
    "print(f'logloss: {score: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6bcebae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "59/59 [==============================] - 0s 4ms/step - loss: 0.1711 - accuracy: 0.9323 - val_loss: 0.2924 - val_accuracy: 0.8820\n",
      "Epoch 2/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.1637 - accuracy: 0.9356 - val_loss: 0.3042 - val_accuracy: 0.8820\n",
      "Epoch 3/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.1588 - accuracy: 0.9369 - val_loss: 0.2867 - val_accuracy: 0.8816\n",
      "Epoch 4/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.1354 - accuracy: 0.9447 - val_loss: 0.2891 - val_accuracy: 0.8820\n",
      "Epoch 5/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.1302 - accuracy: 0.9465 - val_loss: 0.3067 - val_accuracy: 0.8812\n",
      "Epoch 6/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.1250 - accuracy: 0.9520 - val_loss: 0.3113 - val_accuracy: 0.8840\n",
      "Epoch 7/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.1228 - accuracy: 0.9507 - val_loss: 0.3173 - val_accuracy: 0.8844\n",
      "Epoch 8/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.1073 - accuracy: 0.9572 - val_loss: 0.3224 - val_accuracy: 0.8860\n",
      "Epoch 9/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.1100 - accuracy: 0.9565 - val_loss: 0.3120 - val_accuracy: 0.8884\n",
      "Epoch 10/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.1044 - accuracy: 0.9589 - val_loss: 0.3243 - val_accuracy: 0.8880\n",
      "Epoch 11/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0917 - accuracy: 0.9639 - val_loss: 0.3319 - val_accuracy: 0.8896\n",
      "Epoch 12/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0897 - accuracy: 0.9629 - val_loss: 0.3336 - val_accuracy: 0.8900\n",
      "Epoch 13/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 0.9649 - val_loss: 0.3350 - val_accuracy: 0.8808\n",
      "Epoch 14/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0864 - accuracy: 0.9679 - val_loss: 0.3457 - val_accuracy: 0.8820\n",
      "Epoch 15/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0804 - accuracy: 0.9697 - val_loss: 0.3409 - val_accuracy: 0.8852\n",
      "Epoch 16/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9757 - val_loss: 0.3657 - val_accuracy: 0.8872\n",
      "Epoch 17/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9719 - val_loss: 0.3528 - val_accuracy: 0.8892\n",
      "Epoch 18/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0676 - accuracy: 0.9733 - val_loss: 0.3700 - val_accuracy: 0.8828\n",
      "Epoch 19/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0675 - accuracy: 0.9745 - val_loss: 0.3884 - val_accuracy: 0.8828\n",
      "Epoch 20/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9769 - val_loss: 0.3801 - val_accuracy: 0.8828\n",
      "Epoch 21/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0652 - accuracy: 0.9749 - val_loss: 0.3811 - val_accuracy: 0.8824\n",
      "Epoch 22/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9788 - val_loss: 0.3983 - val_accuracy: 0.8880\n",
      "Epoch 23/50\n",
      "59/59 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9759 - val_loss: 0.3886 - val_accuracy: 0.8896\n",
      "313/313 [==============================] - 0s 760us/step\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "epochs  = 50\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience = 20, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(tr_x, tr_y, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(va_x, va_y), callbacks=[early_stopping])\n",
    "pred=model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a3bcc16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logloss: 0.3720\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train = pd.read_csv('./input/sample-data/train_preprocessed_onehot.csv')\n",
    "train_x = train.drop(['target'], axis=1)\n",
    "train_y = train['target']\n",
    "test_x = pd.read_csv('./input/sample-data/test_preprocessed_onehot.csv')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\n",
    "tr_idx, va_idx = list(kf.split(train_x))[0]\n",
    "tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "tr_x = scaler.fit_transform(tr_x)\n",
    "va_x = scaler.transform(va_x)\n",
    "test_x = scaler.transform(test_x)\n",
    "\n",
    "model = LogisticRegression(C=1)\n",
    "model.fit(tr_x, tr_y)\n",
    "va_pred = model.predict_proba(va_x)\n",
    "score = log_loss(va_y, va_pred)\n",
    "print(f'logloss: {score:.4f}')\n",
    "\n",
    "pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13160d61",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[1;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(C\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtr_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m va_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(va_x)\n\u001b[1;32m     22\u001b[0m score \u001b[38;5;241m=\u001b[39m log_loss(va_y, va_pred)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1508\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1506\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1508\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1516\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/sklearn/base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/sklearn/utils/validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 964\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[1;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/sklearn/utils/validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    795\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    797\u001b[0m         )\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 800\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    803\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.3/lib/python3.10/site-packages/sklearn/utils/validation.py:114\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    108\u001b[0m         allow_nan\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many()\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan\n\u001b[1;32m    111\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m    112\u001b[0m     ):\n\u001b[1;32m    113\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    115\u001b[0m             msg_err\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    116\u001b[0m                 type_err, msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    117\u001b[0m             )\n\u001b[1;32m    118\u001b[0m         )\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e15ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
