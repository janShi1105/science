{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqPlmpIFBebARt75zrpTjZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janShi1105/science/blob/main/ML16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2O6CxFAHXQt",
        "outputId": "b0c6d5a3-f68b-4993-a3c7-c2b0b9bb6933"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W_xh shape: (5, 2)\n",
            "W_oo shape: (2, 2)\n",
            "b_h shape: (2,)\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.random.set_seed(1)\n",
        "rnn_layer = tf.keras.layers.SimpleRNN(units=2, use_bias= True, return_sequences=True)\n",
        "rnn_layer.build(input_shape=(None, None, 5))\n",
        "w_xh, w_oo, b_h = rnn_layer.weights\n",
        "print('W_xh shape:', w_xh.shape)\n",
        "print('W_oo shape:', w_oo.shape)\n",
        "print('b_h shape:', b_h.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_seq = tf.convert_to_tensor([[1.0]*5, [2.0]*5, [3.0]*5], dtype=tf.float32)\n",
        "output = rnn_layer(tf.reshape(x_seq, shape=(1,3,5)))\n",
        "out_man = []\n",
        "for t in range(len(x_seq)):\n",
        "  xt = tf.reshape(x_seq[t], (1,5))\n",
        "  print('Time step {}'.format(t))\n",
        "  print('    Input           :', xt.numpy())\n",
        "\n",
        "  ht = tf.matmul(xt, w_xh) + b_h\n",
        "  print('    Hidden        :', ht.numpy())\n",
        "\n",
        "  if t>0:\n",
        "    prev_o = out_man[t-1]\n",
        "  else:\n",
        "    prev_o = tf.zeros(shape=(ht.shape))\n",
        "  ot = ht + tf.matmul(prev_o, w_oo)\n",
        "  ot = tf.math.tanh(ot)\n",
        "  out_man.append(ot)\n",
        "  print('      Output (manual)   :', ot.numpy())\n",
        "  print('      SimpleRNN output: '.format(t), output[0][t].numpy())\n",
        "  print()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBmMQNoPKaDA",
        "outputId": "eacc8fd2-ba8f-4f7b-df85-f084f13122ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time step 0\n",
            "    Input           : [[1. 1. 1. 1. 1.]]\n",
            "    Hidden        : [[0.4775737  0.21143436]]\n",
            "      Output (manual)   : [[0.44429833 0.20833899]]\n",
            "      SimpleRNN output:  [0.44429833 0.20833899]\n",
            "\n",
            "Time step 1\n",
            "    Input           : [[2. 2. 2. 2. 2.]]\n",
            "    Hidden        : [[0.9551474  0.42286873]]\n",
            "      Output (manual)   : [[0.8925385  0.48455504]]\n",
            "      SimpleRNN output:  [0.8925385  0.48455504]\n",
            "\n",
            "Time step 2\n",
            "    Input           : [[3. 3. 3. 3. 3.]]\n",
            "    Hidden        : [[1.4327211 0.6343031]]\n",
            "      Output (manual)   : [[0.983985  0.7219829]]\n",
            "      SimpleRNN output:  [0.983985  0.7219829]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT7OhKDyQ7ph",
        "outputId": "9e91cfcf-64fe-4d46-f165-299c6754e49b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('drive/MyDrive/movie_data.csv', encoding='utf-8')"
      ],
      "metadata": {
        "id": "xLaxkLCcUJRl"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrHPYmU6UfzS",
        "outputId": "dca8af26-54b0-4a58-b322-6f6f0c645fc8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = df.pop('sentiment')\n",
        "ds_raw = tf.data.Dataset.from_tensor_slices((df.values, target.values))\n",
        "for ex in ds_raw.take(3):\n",
        "  tf.print(ex[0].numpy()[0][:50], ex[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIskxt2sUltU",
        "outputId": "36881a8a-b9b2-4a11-c56d-a15feda33e9e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'In 1974, the teenager Martha Moxley (Maggie Grace)' 1\n",
            "b'OK... so... I really like Kris Kristofferson and h' 0\n",
            "b'***SPOILER*** Do not read this, if you think about' 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(1)\n",
        "ds_raw= ds_raw.shuffle(50000, reshuffle_each_iteration=False)\n",
        "ds_raw_test = ds_raw.take(25000)\n",
        "ds_raw_train_valid = ds_raw.skip(25000)\n",
        "ds_raw_train = ds_raw_train_valid.take(20000)\n",
        "ds_raw_valid = ds_raw_train_valid.skip(20000)"
      ],
      "metadata": {
        "id": "ojUWsUMeVHjE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "tokenizer = tfds.deprecated.text.Tokenizer()\n",
        "token_counts = Counter()\n",
        "for example in ds_raw_train:\n",
        "  tokens = tokenizer.tokenize(example[0].numpy()[0])\n",
        "  token_counts.update(tokens)\n",
        "\n",
        "print('Vocab-size:', len(token_counts))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wipY24dtVhyY",
        "outputId": "7e4f6874-8bd5-4f3f-cf17-718c7cecbf41"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab-size: 87007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe3oNyLFV_d0",
        "outputId": "3de09082-6ee1-42c9-e27f-073fa491f7fb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.10.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras<2.11,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: tensorboard<2.11,>=2.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0.7)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.48.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorflow --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KszyM76cWm0h",
        "outputId": "37d09479-df80-4055-c89d-bbf2c7841afa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: tensorflow: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = tfds.deprecated.text.TokenTextEncoder(token_counts)\n",
        "example_str = 'This is an example!'\n",
        "print(encoder.encode(example_str))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIZmy4t2onEx",
        "outputId": "d4faa385-b3b5-4f10-d77a-6cadc2515829"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[232, 9, 270, 1123]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text_tensor, label):\n",
        "  text = text_tensor.numpy()[0]\n",
        "  encoded_text = encoder.encode(text)\n",
        "  return encoded_text, label"
      ],
      "metadata": {
        "id": "lDUCPXrTt6zJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_map_fn(text, label):\n",
        "  return tf.py_function(encode, inp=[text, label], Tout=(tf.int64, tf.int64))\n",
        "\n",
        "ds_train = ds_raw_train.map(encode_map_fn)\n",
        "ds_valid = ds_raw_valid.map(encode_map_fn)\n",
        "ds_test = ds_raw_test.map(encode_map_fn)\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "for example in ds_train.shuffle(1000).take(5):\n",
        "  print('Sequnece length: ', example[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Skd0Jw1SuSzL",
        "outputId": "694f0735-646d-4ba0-cdd6-9da1a6578d1d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequnece length:  (24,)\n",
            "Sequnece length:  (179,)\n",
            "Sequnece length:  (262,)\n",
            "Sequnece length:  (535,)\n",
            "Sequnece length:  (130,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_subset = ds_train.take(8)\n",
        "for example in ds_subset:\n",
        "  print('Individual size: ', example[0].shape)\n",
        "  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow4iZXeHu5Id",
        "outputId": "a22c6e03-4f51-4d9d-f4b6-28b12f231768"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Individual size:  (119,)\n",
            "Individual size:  (688,)\n",
            "Individual size:  (308,)\n",
            "Individual size:  (204,)\n",
            "Individual size:  (326,)\n",
            "Individual size:  (240,)\n",
            "Individual size:  (127,)\n",
            "Individual size:  (453,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds_batched = ds_subset.padded_batch(4, padded_shapes=([-1], []))\n",
        "for batch in ds_batched:\n",
        "  print('Batch dimension: ', batch[0].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbfRJy8cyXVH",
        "outputId": "ef5734f3-f24d-4a69-b3be-0e5652f36e38"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch dimension:  (4, 688)\n",
            "Batch dimension:  (4, 453)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = ds_train.padded_batch(32, padded_shapes=([-1], []))\n",
        "valid_data = ds_valid.padded_batch(32, padded_shapes=([-1], []))\n",
        "test_data = ds_test.padded_batch(32, padded_shapes=([-1], []))"
      ],
      "metadata": {
        "id": "sCbm6CRKyiJv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "model = tf.keras.Sequential()\n",
        "model.add(Embedding(input_dim=100, output_dim=6, input_length=20, name='embed-layer'))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjIdjJYJy48s",
        "outputId": "e79270a0-0f92-406c-8771-bed6f310bf37"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embed-layer (Embedding)     (None, 20, 6)             600       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 600\n",
            "Trainable params: 600\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import SimpleRNN\n",
        "from tensorflow.keras.layers import Dense\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=1000, output_dim=32))\n",
        "model.add(SimpleRNN(32, return_sequences=True))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8ocXEgHz0oQ",
        "outputId": "b9346c91-c1da-4987-f9b9-d0fc0643c63b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 32)          32000     \n",
            "                                                                 \n",
            " simple_rnn_1 (SimpleRNN)    (None, None, 32)          2080      \n",
            "                                                                 \n",
            " simple_rnn_2 (SimpleRNN)    (None, 32)                2080      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 36,193\n",
            "Trainable params: 36,193\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 20\n",
        "vocab_size = len(token_counts) + 2\n",
        "tf.random.set_seed(1)\n",
        "bi_lstm_model = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, name='embed-layer'), \n",
        "      #tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, name='lstm-layer'), name='bidir-lstm'),\n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.RNN(tf.keras.layers.LSTMCell(64))),\n",
        "      tf.keras.layers.Dense(64, activation='relu'),\n",
        "     tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ]\n",
        ")\n",
        "bi_lstm_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCT-3uov09aC",
        "outputId": "7376606b-e3e1-46f8-b033-4d9e30b0aba1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embed-layer (Embedding)     (None, None, 20)          1740180   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 128)              43520     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,792,021\n",
            "Trainable params: 1,792,021\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bi_lstm_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3), loss=tf.keras.losses.BinaryCrossentropy(from_logits=False), metrics=['accuracy'])\n",
        "history = bi_lstm_model.fit(train_data, validation_data=valid_data, epochs=10)\n",
        "test_results = bi_lstm_model.evaluate(test_data)\n",
        "print('Test Acc.: {:.2f}%'.format(test_results[1]*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rLTDxVt13J7",
        "outputId": "6fe533bf-ff84-44db-8af9-bcc6c80bae01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "202/625 [========>.....................] - ETA: 24:39 - loss: 0.6294 - accuracy: 0.6304"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vDQ1az7L2oLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def preprocess_datasets(ds_raw_train, ds_raw_valid, ds_raw_test, max_seq_length=None, batch_size=32):\n",
        "  tokenizer = tfds.deprecated.text.Tokenizer()\n",
        "  token_counts = Counter()\n",
        "\n",
        "  for example in ds_raw_train:\n",
        "    tokens = tokenizer.tokenize(example[0].numpy()[0])\n",
        "    if max_seq_length is not None:\n",
        "      tokens = tokens[-max_seq_length:]\n",
        "    token_counts.update(tokens)\n",
        "\n",
        "  print('Vocab-size:', len(token_counts))\n",
        "\n",
        "  encoder = tfds.deprecated.text.TokenTextEncoder(token_counts)\n",
        "  def encode(text_tensor, label):\n",
        "    text = text_tensor.numpy()[0]\n",
        "    encoded_text = encoder.encode(text)\n",
        "    if max_seq_length is not None:\n",
        "      encoded_text = encoded_text[-max_seq_length:]\n",
        "    return encoded_text, label\n",
        "\n",
        "  def encode_map_fn(text, label):\n",
        "    return tf.py_function(encode, inp=[text, label], Tout=(tf.int64, tf.int64))\n",
        "\n",
        "  ds_train = ds_raw_train.map(encode_map_fn)\n",
        "  ds_valid = ds_raw_valid.map(encode_map_fn)\n",
        "  ds_test = ds_raw_test(encode_map_fn)\n",
        "\n",
        "  train_data = ds_train.padded_batch(batch_size, padded_shapes=([-1], []))\n",
        "  valid_data = ds_valid.padded_batch(batch_size, padded_shapes=([-1], []))\n",
        "  test_data = ds_test.padded_batch(batch_size, padded_shapes=([-1], []))\n",
        "  \n",
        "  return (train_data, valid_data, test_data, len(token_counts))"
      ],
      "metadata": {
        "id": "F35mT6Cu42Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iPCWdU28pBNH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}