{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71724a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length:  1130711\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('1268-0.txt', 'r') as fp:\n",
    "  text = fp.read()\n",
    "\n",
    "start_idx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_idx = text.find('End of the Project Gutenberg')\n",
    "text = text[start_idx:end_idx]\n",
    "char_set = set(text)\n",
    "print('Total Length: ', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e62d30d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1268-0.txt                      \u001b[34mexamples\u001b[m\u001b[m\r\n",
      "\u001b[34m1st_flask_app_1\u001b[m\u001b[m                 figpath.svg\r\n",
      "ML10.ipynb                      figpath2.png\r\n",
      "ML11.ipynb                      index.html\r\n",
      "ML13.ipynb                      \u001b[34mkaggle\u001b[m\u001b[m\r\n",
      "ML16-2.ipynb                    \u001b[34mkagglebook-master\u001b[m\u001b[m\r\n",
      "ML3.ipynb                       machineLearning.ipynb\r\n",
      "ML6.ipynb                       machineLearning2.ipynb\r\n",
      "ML8.ipynb                       \u001b[34mml\u001b[m\u001b[m\r\n",
      "ML9.ipynb                       mnist_scaled.npz\r\n",
      "\u001b[34mPmaster\u001b[m\u001b[m                         movie_data.csv\r\n",
      "README.md                       \u001b[34mmovieclassifier\u001b[m\u001b[m\r\n",
      "\u001b[34mRStudio\u001b[m\u001b[m                         \u001b[34mmy-test-env\u001b[m\u001b[m\r\n",
      "\u001b[34maclImdb\u001b[m\u001b[m                         mydata.csv\r\n",
      "array_archive.npz               mydata.h5\r\n",
      "array_compresed.npz             mydata.sqlite\r\n",
      "\u001b[34mcat_dog_images\u001b[m\u001b[m                  numpy01.py\r\n",
      "chapter 10.ipynb                plot_decision_regions_script.py\r\n",
      "chapter1.ipynb                  present A.ipynb\r\n",
      "chapter11.ipynb                 push.command\r\n",
      "chapter12.ipynb                 push_from_main.command\r\n",
      "chapter13.1.ipynb               push_from_work.command\r\n",
      "chapter13.ipynb                 pw.command\r\n",
      "chapter14.ipynb                 \u001b[34msamplecode_20201021\u001b[m\u001b[m\r\n",
      "chapter4.ipynb                  sk00.ipynb\r\n",
      "chapter5.ipynb                  some_array.npy\r\n",
      "chapter6.ipynb                  statistic.ipynb\r\n",
      "chapter7.ipynb                  t10k-images-idx3-ubyte\r\n",
      "chapter8.ipynb                  t10k-labels-idx1-ubyte\r\n",
      "chapter9.1.ipynb                \u001b[34mtitanic\u001b[m\u001b[m\r\n",
      "chapter9.ipynb                  train-images-idx3-ubyte\r\n",
      "cv_sample.py                    train-labels-idx1-ubyte\r\n",
      "\u001b[34mdatasets\u001b[m\u001b[m                        tree.png\r\n",
      "example-image.png               \u001b[34m~\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b98536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Charactor:  85\n"
     ]
    }
   ],
   "source": [
    "print('Unique Charactor: ',len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b48a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape:  (1130711,)\n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i, ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "text_encoded = np.array([char2int[ch] for ch in text], dtype=np.int32)\n",
    "print('Text encoded shape: ', text_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "065035ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE MYSTERIOUS  == Encodind ==> [48 36 33  1 41 53 47 48 33 46 37 43 49 47  1]\n"
     ]
    }
   ],
   "source": [
    "print(text[:15], '== Encodind ==>', text_encoded[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e344f224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37 47 40 29 42 32] == Reverse ==> ISLAND\n"
     ]
    }
   ],
   "source": [
    "print(text_encoded[15:21], '== Reverse ==>', ''.join(char_array[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68243b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 -> T\n",
      "36 -> H\n",
      "33 -> E\n",
      "1 ->  \n",
      "41 -> M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 19:01:05.095477: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
    "for ex in ds_text_encoded.take(5):\n",
    "    print('{} -> {}'.format(ex.numpy(), char_array[ex.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47ca252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length+1\n",
    "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True)\n",
    "def split_input_target(chunk):\n",
    "    input_seq = chunk[:-1]\n",
    "    target_seq = chunk[1:]\n",
    "    return input_seq, target_seq\n",
    "\n",
    "ds_sequences = ds_chunks.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4defc99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input(x):  'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTER'\n",
      "Target (y):  'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n",
      " Input(x):  'OUS ISLAND\\n\\nby Jules Verne\\n\\n1874\\n\\n\\n\\n\\nPAR'\n",
      "Target (y):  'US ISLAND\\n\\nby Jules Verne\\n\\n1874\\n\\n\\n\\n\\nPART'\n"
     ]
    }
   ],
   "source": [
    "for example in ds_sequences.take(2):\n",
    "    print(' Input(x): ', repr(''.join(char_array[example[0].numpy()])))\n",
    "    print('Target (y): ', repr(''.join(char_array[example[1].numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "955913c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE  = 64\n",
    "BUFFER_SIZE = 10000\n",
    "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8143a68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 256)         21760     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 512)         1574912   \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 85)          43605     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,640,277\n",
      "Trainable params: 1,640,277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim), \n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "charset_size = len(char_array)\n",
    "embedding_dim = 256\n",
    "rnn_units = 512\n",
    "tf.random.set_seed(1)\n",
    "model = build_model(vocab_size=charset_size, embedding_dim = embedding_dim, rnn_units=rnn_units)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "783235af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04b1bb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "431/431 [==============================] - 102s 232ms/step - loss: 2.3364\n",
      "Epoch 2/10\n",
      "431/431 [==============================] - 104s 239ms/step - loss: 1.7606\n",
      "Epoch 3/10\n",
      "431/431 [==============================] - 105s 241ms/step - loss: 1.5569\n",
      "Epoch 4/10\n",
      "431/431 [==============================] - 103s 238ms/step - loss: 1.4396\n",
      "Epoch 5/10\n",
      "431/431 [==============================] - 124s 286ms/step - loss: 1.3651\n",
      "Epoch 6/10\n",
      "431/431 [==============================] - 122s 279ms/step - loss: 1.3128\n",
      "Epoch 7/10\n",
      "431/431 [==============================] - 106s 245ms/step - loss: 1.2730\n",
      "Epoch 8/10\n",
      "431/431 [==============================] - 112s 258ms/step - loss: 1.2423\n",
      "Epoch 9/10\n",
      "431/431 [==============================] - 102s 235ms/step - loss: 1.2155\n",
      "Epoch 10/10\n",
      "431/431 [==============================] - 101s 234ms/step - loss: 1.1926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x128e2dd20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60cff193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities: [0.33333334 0.33333334 0.33333334]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "logits = [[1.0, 1.0, 1.0]]\n",
    "print('Probabilities:', tf.math.softmax(logits).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b91e3813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0, 0, 1, 2, 0, 0, 0, 0, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "samples = tf.random.categorical(logits=logits, num_samples=10)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "297e6b9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities:  [0.10650698 0.10650698 0.78698605]\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "logits = [[1.0, 1.0, 3.0]]\n",
    "print('Probabilities: ', tf.math.softmax(logits).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3bee067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[2, 0, 2, 2, 2, 0, 1, 2, 2, 0]])\n"
     ]
    }
   ],
   "source": [
    "samples = tf.random.categorical(logits=logits, num_samples=10)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5499be8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(model, starting_str, len_generated_text=500, max_input_length = 40, scale_factor=1.0):\n",
    "    encoded_input = [char2int[s] for s in starting_str]\n",
    "    encoded_input = tf.reshape(encoded_input, (1,-1))\n",
    "    \n",
    "    generated_str = starting_str\n",
    "    \n",
    "    model.reset_states()\n",
    "    for i in  range(len_generated_text):\n",
    "        logits = model(encoded_input)\n",
    "        logits = tf.squeeze(logits, 0)\n",
    "        \n",
    "        scaled_logits = logits * scale_factor\n",
    "        new_char_idx = tf.random.categorical(scaled_logits, num_samples=1)\n",
    "        new_char_idx = tf.squeeze(new_char_idx)[-1].numpy()\n",
    "        generated_str += str(char_array[new_char_idx])\n",
    "        new_char_idx = tf.expand_dims([new_char_idx], 0)\n",
    "        encoded_input = tf.concat([encoded_input, new_char_idx], axis=1)\n",
    "        encoded_input = encoded_input[:, -max_input_length:]\n",
    "        \n",
    "    return generated_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83e93ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[48 62 59  1 63 73 66 55 68 58]], shape=(1, 10), dtype=int32)\n",
      "The island is our bead up, and the work his shailed\n",
      "sight\n",
      "began to say, the number of\n",
      "June his cheeks to piece sharm nothing to give an hour grunt and\n",
      "all the wished on the electrory relished it in which they saw that the cart without death to the operation of one of the house, belonged, could leeping up from her, and\n",
      "he bed of\n",
      "Uneorably that Spilett’s rays had been lovely to me.”\n",
      "\n",
      "“And when the\n",
      "arch till, Pencroft, were it not from this point mawnessed. The dails were to be knowledged a word: Lincoln Isl\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str='The island'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f50237d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities before scaling:  [0.10650698 0.10650698 0.78698604]\n"
     ]
    }
   ],
   "source": [
    "logits = np.array([[1.0, 1.0, 3.0]])\n",
    "print('Probabilities before scaling: ', tf.math.softmax(logits).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f78eada5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities after scaling with 0.5:  [0.21194156 0.21194156 0.57611688]\n"
     ]
    }
   ],
   "source": [
    "print('Probabilities after scaling with 0.5: ', tf.math.softmax(0.5*logits).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a880d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities after scaling with 0.1:  [0.31042377 0.31042377 0.37915245]\n"
     ]
    }
   ],
   "source": [
    "print('Probabilities after scaling with 0.1: ', tf.math.softmax(0.1 *logits).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "000ae78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[48 62 59  1 63 73 66 55 68 58]], shape=(1, 10), dtype=int32)\n",
      "The island was simple at least to be some motionless sent and seen that the rock was a sort of sea, which in the convicts were on the shore of the colonists were to be found in the signal to do an island with the sea, which\n",
      "the trateat of the forest with start in the engineer, the settlers were not even destroyed the animal point of the subject could, that is to say, the situation of the lake, said the profession of the corral was profter in the neight of the cart was to be seen to the corral. From time t\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str='The island', scale_factor=2.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7214d471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island harng capa.\n",
      "Weau; 7Natiasquin;, word opbark, safe!-- housaipseliquun.\n",
      "Gide.\n",
      "The asted kilo0m, ildeplue no proristence. Gifes far, grying\n",
      "jacamaritlesstsla, mile! Har?r Would drook Uly has’ kill. Po.2\n",
      "found sprtaf\n",
      "clecticulce Harding tolse. Uso, peneplation, anr; there-botainst his admirenhistence.”\n",
      "\n",
      "1er.\n",
      "FH Neial,\n",
      "jo af its twon Masboarmy;” re will\n",
      "aquered!” Twolveople’c natious, sowe\n",
      "/salend, we end, for this\n",
      "frigtfads. Yousavel? Had\n",
      "he whuensif-Scabforuely?” fifthered howes- yeighb, Harding, \n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str = 'The island', scale_factor=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d26d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
