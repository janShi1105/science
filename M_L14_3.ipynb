{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNX9jkW81ykwA5Fsrs7Am5g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/janShi1105/science/blob/main/M_L14_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uA7biTy6bMzg"
      },
      "outputs": [],
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "BUFFER_SIZE = 10000\n",
        "BATCH_SIZE = 64\n",
        "NUM_EPOCHS = 20\n",
        "steps_per_epoch = np.ceil(60000/ BATCH_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(item):\n",
        "  image = item['image']\n",
        "  label = item['label']\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "  image = tf.reshape(image, (-1,))\n",
        "  return {'image-pixels': image}, label[..., tf.newaxis]"
      ],
      "metadata": {
        "id": "HyY2VGBLbTpl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_input_fn():\n",
        "  datasets = tfds.load(name='mnist')\n",
        "  mnist_train = datasets['train']\n",
        "  dataset = mnist_train.map(preprocess)\n",
        "  dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "  dataset = dataset.batch(BATCH_SIZE)\n",
        "  return dataset.repeat()\n",
        "\n",
        "def eval_input_fn():\n",
        "  datasets = tfds.load(name='mnist')\n",
        "  mnist_test = datasets['test']\n",
        "  dataset = mnist_test.map(preprocess).batch(BATCH_SIZE)\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "pVCzNhYobVJ7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_feature_column = tf.feature_column.numeric_column(key='image-pixels', shape=(28*28))"
      ],
      "metadata": {
        "id": "zbks5lRVbW5d"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dnn_classifier = tf.estimator.DNNClassifier(feature_columns=[image_feature_column], hidden_units=[32,16], n_classes=10, model_dir='models/mnist-dnn/')"
      ],
      "metadata": {
        "id": "h6AQa9DQbZH9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dnn_classifier.train(input_fn=train_input_fn, steps=NUM_EPOCHS * steps_per_epoch)\n",
        "eval_result = dnn_classifier.evaluate(input_fn=eval_input_fn)\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPoNbA8Gbal5",
        "outputId": "e47c1d2f-0218-4e82-f88d-76dc319591dc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1161: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file utilities to get mtimes.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 22480 vs previous value: 22480. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'accuracy': 0.8985, 'average_loss': 0.36893693, 'loss': 0.3687791, 'global_step': 37520}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(1)\n",
        "np.random.seed(1)\n",
        "x = np.random.uniform(low=-1, high=1, size=(200,2))\n",
        "y = np.ones(len(x))\n",
        "y[x[:,0] * x[:,1]<0] = 0\n",
        "x_train = x[:100, :]\n",
        "y_train = y[:100]\n",
        "x_valid = x[100:, :]\n",
        "y_valid = y[100:]"
      ],
      "metadata": {
        "id": "zt5E8s_Sb2s4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Input(shape=(2,), name='input-features'),\n",
        "    tf.keras.layers.Dense(units=4, activation='relu'),\n",
        "    tf.keras.layers.Dense(units=4, activation='relu'), \n",
        "    tf.keras.layers.Dense(units=4, activation='relu'), \n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])"
      ],
      "metadata": {
        "id": "YIQnZ5Oucg2X"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_input_fn(x_train,  y_train, batch_size=8):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(({'input-features': x_train}, y_train.reshape(-1,1)))\n",
        "  return dataset.shuffle(100).repeat().batch(batch_size)\n",
        "\n",
        "def eval_input_fn(x_test, y_test=None, batch_size=8):\n",
        "  if y_test is None:\n",
        "    dataset = tf.data.Dataset.from_tensor_slices({'input-features': x_test})\n",
        "  else:\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(({'input-features': x_test}, y_test.reshape(-1,1)))\n",
        "\n",
        "    return dataset.batch(batch_size)\n",
        "\n",
        "features = [tf.feature_column.numeric_column(key='input-features:', shape=(2,))]"
      ],
      "metadata": {
        "id": "iD8nVTebdDWP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.SGD(), loss=tf.keras.losses.BinaryCrossentropy(), metrics=[tf.keras.metrics.BinaryAccuracy()])\n",
        "my_estimator = tf.keras.estimator.model_to_estimator(keras_model=model, model_dir = 'models/estimator-for-XOR/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em7OK520d8f0",
        "outputId": "a8992fa0-8c4c-4303-a6df-0dcf85808b36"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 200\n",
        "batch_size = 2\n",
        "steps_per_epoch = np.ceil(len(x_train) / batch_size)\n",
        "my_estimator.train(input_fn=lambda: train_input_fn(x_train, y_train, batch_size), steps=num_epochs * steps_per_epoch)\n",
        "my_estimator.evaluate(input_fn = lambda: eval_input_fn(x_valid, y_valid, batch_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVtFxa5vebNT",
        "outputId": "75e3647c-5f14-416d-9048-52c0eacb4956"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 1012 vs previous value: 1012. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 3461 vs previous value: 3461. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 4214 vs previous value: 4214. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates = self.state_updates\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'binary_accuracy': 0.97, 'loss': 0.08625225, 'global_step': 10000}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S6-htMh-e1f9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}