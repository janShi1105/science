{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71724a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Length:  1130711\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with open('1268-0.txt', 'r') as fp:\n",
    "  text = fp.read()\n",
    "\n",
    "start_idx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_idx = text.find('End of the Project Gutenberg')\n",
    "text = text[start_idx:end_idx]\n",
    "char_set = set(text)\n",
    "print('Total Length: ', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e62d30d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1268-0.txt                      \u001b[34mexamples\u001b[m\u001b[m\r\n",
      "\u001b[34m1st_flask_app_1\u001b[m\u001b[m                 figpath.svg\r\n",
      "ML10.ipynb                      figpath2.png\r\n",
      "ML11.ipynb                      index.html\r\n",
      "ML13.ipynb                      \u001b[34mkaggle\u001b[m\u001b[m\r\n",
      "ML16-2.ipynb                    \u001b[34mkagglebook-master\u001b[m\u001b[m\r\n",
      "ML3.ipynb                       machineLearning.ipynb\r\n",
      "ML6.ipynb                       machineLearning2.ipynb\r\n",
      "ML8.ipynb                       \u001b[34mml\u001b[m\u001b[m\r\n",
      "ML9.ipynb                       mnist_scaled.npz\r\n",
      "\u001b[34mPmaster\u001b[m\u001b[m                         movie_data.csv\r\n",
      "README.md                       \u001b[34mmovieclassifier\u001b[m\u001b[m\r\n",
      "\u001b[34mRStudio\u001b[m\u001b[m                         \u001b[34mmy-test-env\u001b[m\u001b[m\r\n",
      "\u001b[34maclImdb\u001b[m\u001b[m                         mydata.csv\r\n",
      "array_archive.npz               mydata.h5\r\n",
      "array_compresed.npz             mydata.sqlite\r\n",
      "\u001b[34mcat_dog_images\u001b[m\u001b[m                  numpy01.py\r\n",
      "chapter 10.ipynb                plot_decision_regions_script.py\r\n",
      "chapter1.ipynb                  present A.ipynb\r\n",
      "chapter11.ipynb                 push.command\r\n",
      "chapter12.ipynb                 push_from_main.command\r\n",
      "chapter13.1.ipynb               push_from_work.command\r\n",
      "chapter13.ipynb                 pw.command\r\n",
      "chapter14.ipynb                 \u001b[34msamplecode_20201021\u001b[m\u001b[m\r\n",
      "chapter4.ipynb                  sk00.ipynb\r\n",
      "chapter5.ipynb                  some_array.npy\r\n",
      "chapter6.ipynb                  statistic.ipynb\r\n",
      "chapter7.ipynb                  t10k-images-idx3-ubyte\r\n",
      "chapter8.ipynb                  t10k-labels-idx1-ubyte\r\n",
      "chapter9.1.ipynb                \u001b[34mtitanic\u001b[m\u001b[m\r\n",
      "chapter9.ipynb                  train-images-idx3-ubyte\r\n",
      "cv_sample.py                    train-labels-idx1-ubyte\r\n",
      "\u001b[34mdatasets\u001b[m\u001b[m                        tree.png\r\n",
      "example-image.png               \u001b[34m~\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11b98536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Charactor:  85\n"
     ]
    }
   ],
   "source": [
    "print('Unique Charactor: ',len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text encoded shape:  (1130711,)\n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i, ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "text_encoded = np.array([char2int[ch] for ch in text], dtype=np.int32)\n",
    "print('Text encoded shape: ', text_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e2b0fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE MYSTERIOUS  == Encodind ==> [48 36 33  1 41 53 47 48 33 46 37 43 49 47  1]\n"
     ]
    }
   ],
   "source": [
    "print(text[:15], '== Encodind ==>', text_encoded[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62680f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37 47 40 29 42 32] == Reverse ==> ISLAND\n"
     ]
    }
   ],
   "source": [
    "print(text_encoded[15:21], '== Reverse ==>', ''.join(char_array[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55a9ca4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 -> T\n",
      "36 -> H\n",
      "33 -> E\n",
      "1 ->  \n",
      "41 -> M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-15 19:01:05.095477: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
    "for ex in ds_text_encoded.take(5):\n",
    "    print('{} -> {}'.format(ex.numpy(), char_array[ex.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "446a4106",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 40\n",
    "chunk_size = seq_length+1\n",
    "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True)\n",
    "def split_input_target(chunk):\n",
    "    input_seq = chunk[:-1]\n",
    "    target_seq = chunk[1:]\n",
    "    return input_seq, target_seq\n",
    "\n",
    "ds_sequences = ds_chunks.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07d3d632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input(x):  'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTER'\n",
      "Target (y):  'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nTHE MYSTERI'\n",
      " Input(x):  'OUS ISLAND\\n\\nby Jules Verne\\n\\n1874\\n\\n\\n\\n\\nPAR'\n",
      "Target (y):  'US ISLAND\\n\\nby Jules Verne\\n\\n1874\\n\\n\\n\\n\\nPART'\n"
     ]
    }
   ],
   "source": [
    "for example in ds_sequences.take(2):\n",
    "    print(' Input(x): ', repr(''.join(char_array[example[0].numpy()])))\n",
    "    print('Target (y): ', repr(''.join(char_array[example[1].numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6d32e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE  = 64\n",
    "BUFFER_SIZE = 10000\n",
    "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4b1ed32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 256)         21760     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, None, 512)         1574912   \n",
      "                                                                 \n",
      " dense (Dense)               (None, None, 85)          43605     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,640,277\n",
      "Trainable params: 1,640,277\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim), \n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "charset_size = len(char_array)\n",
    "embedding_dim = 256\n",
    "rnn_units = 512\n",
    "tf.random.set_seed(1)\n",
    "model = build_model(vocab_size=charset_size, embedding_dim = embedding_dim, rnn_units=rnn_units)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e468eec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44719163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "431/431 [==============================] - 102s 232ms/step - loss: 2.3364\n",
      "Epoch 2/10\n",
      "431/431 [==============================] - 104s 239ms/step - loss: 1.7606\n",
      "Epoch 3/10\n",
      "431/431 [==============================] - 105s 241ms/step - loss: 1.5569\n",
      "Epoch 4/10\n",
      "233/431 [===============>..............] - ETA: 46s - loss: 1.4515"
     ]
    }
   ],
   "source": [
    "model.fit(ds, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff0ce27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "logits = [[1.0, 1.0, 1.0]]\n",
    "print('Probabilities:', tf.math.softmax(logits).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae427727",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = tf.random.categorial(logits=logits, num_samples=10)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880d3ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "logits = [[1.0, 1.0, 3.0]]\n",
    "print('Probabilities: ', tf.math.softmax(logits).numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c381b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = tf.random.categorical(logits=logits, num_sample=10)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ad7fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
